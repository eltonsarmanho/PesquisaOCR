#!/usr/bin/env python3
"""
Script para verificar e configurar depend√™ncias GPU para OCR.
"""

import subprocess
import sys
import os

def executar_comando(comando):
    """Executa um comando shell e retorna o resultado."""
    try:
        resultado = subprocess.run(comando, shell=True, capture_output=True, text=True, check=True)
        return resultado.stdout.strip(), True
    except subprocess.CalledProcessError as e:
        return e.stderr.strip(), False

def verificar_nvidia_gpu():
    """Verifica se h√° GPU NVIDIA dispon√≠vel."""
    print("=== VERIFICA√á√ÉO DE GPU NVIDIA ===")
    
    # Verificar nvidia-smi
    output, sucesso = executar_comando("nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits")
    
    if sucesso:
        print("‚úÖ GPU NVIDIA detectada:")
        linhas = output.split('\n')
        for i, linha in enumerate(linhas):
            if linha.strip():
                nome, memoria = linha.split(', ')
                print(f"   GPU {i}: {nome.strip()} ({memoria.strip()} MB)")
        return True
    else:
        print("‚ùå Nenhuma GPU NVIDIA detectada ou nvidia-smi n√£o instalado")
        return False

def verificar_cuda():
    """Verifica instala√ß√£o do CUDA."""
    print("\n=== VERIFICA√á√ÉO DO CUDA ===")
    
    # Verificar nvcc
    output, sucesso = executar_comando("nvcc --version")
    
    if sucesso:
        # Extrair vers√£o CUDA
        linhas = output.split('\n')
        for linha in linhas:
            if 'release' in linha.lower():
                print(f"‚úÖ CUDA instalado: {linha.strip()}")
                return True
    
    print("‚ùå CUDA n√£o encontrado ou nvcc n√£o est√° no PATH")
    return False

def verificar_pytorch_cuda():
    """Verifica se PyTorch tem suporte CUDA."""
    print("\n=== VERIFICA√á√ÉO PYTORCH + CUDA ===")
    
    try:
        import torch
        cuda_disponivel = torch.cuda.is_available()
        
        if cuda_disponivel:
            print(f"‚úÖ PyTorch com CUDA dispon√≠vel")
            print(f"   Vers√£o CUDA: {torch.version.cuda}")
            print(f"   N√∫mero de GPUs: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
            return True
        else:
            print("‚ùå PyTorch instalado mas sem suporte CUDA")
            return False
            
    except ImportError:
        print("‚ùå PyTorch n√£o instalado")
        return False

def verificar_paddlepaddle_gpu():
    """Verifica se PaddlePaddle tem suporte GPU."""
    print("\n=== VERIFICA√á√ÉO PADDLEPADDLE + GPU ===")
    
    try:
        import paddle
        gpu_disponivel = paddle.is_compiled_with_cuda()
        
        if gpu_disponivel:
            print("‚úÖ PaddlePaddle com GPU dispon√≠vel")
            return True
        else:
            print("‚ùå PaddlePaddle instalado mas sem suporte GPU")
            return False
            
    except ImportError:
        print("‚ùå PaddlePaddle n√£o instalado")
        return False

def instalar_dependencias_gpu():
    """Sugere comandos para instalar depend√™ncias GPU."""
    print("\n=== INSTALA√á√ÉO DE DEPEND√äNCIAS GPU ===")
    
    print("Para instalar suporte GPU, execute os comandos abaixo:")
    print()
    
    # PyTorch com CUDA
    print("üì¶ PyTorch com CUDA (para EasyOCR):")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    print()
    
    # PaddlePaddle GPU
    print("üì¶ PaddlePaddle GPU (para PaddleOCR):")
    print("   pip install paddlepaddle-gpu")
    print()
    
    # EasyOCR
    print("üì¶ EasyOCR:")
    print("   pip install easyocr")
    print()
    
    print("‚ö†Ô∏è  IMPORTANTE:")
    print("   - Certifique-se de ter drivers NVIDIA atualizados")
    print("   - CUDA Toolkit deve estar instalado (vers√£o compat√≠vel)")
    print("   - Reinicie o terminal ap√≥s a instala√ß√£o")

def testar_performance_basica():
    """Testa performance b√°sica de GPU vs CPU."""
    print("\n=== TESTE DE PERFORMANCE ===")
    
    try:
        import time
        import torch
        
        if torch.cuda.is_available():
            # Teste simples de performance GPU vs CPU
            size = 1000
            
            # CPU
            start = time.time()
            cpu_tensor = torch.randn(size, size)
            cpu_result = torch.mm(cpu_tensor, cpu_tensor)
            cpu_time = time.time() - start
            
            # GPU
            start = time.time()
            gpu_tensor = torch.randn(size, size).cuda()
            gpu_result = torch.mm(gpu_tensor, gpu_tensor)
            torch.cuda.synchronize()  # Garantir que a opera√ß√£o termine
            gpu_time = time.time() - start
            
            print(f"‚è±Ô∏è  Multiplica√ß√£o de matrizes {size}x{size}:")
            print(f"   CPU: {cpu_time:.4f}s")
            print(f"   GPU: {gpu_time:.4f}s")
            print(f"   Speedup: {cpu_time/gpu_time:.2f}x")
            
        else:
            print("‚ùå GPU n√£o dispon√≠vel para teste")
            
    except ImportError:
        print("‚ùå PyTorch n√£o instalado - n√£o √© poss√≠vel testar")

def main():
    """Fun√ß√£o principal."""
    print("üîß CONFIGURA√á√ÉO GPU PARA OCR")
    print("=" * 50)
    
    # Verifica√ß√µes
    gpu_nvidia = verificar_nvidia_gpu()
    cuda_instalado = verificar_cuda()
    pytorch_cuda = verificar_pytorch_cuda()
    paddle_gpu = verificar_paddlepaddle_gpu()
    
    # Resumo
    print("\n=== RESUMO ===")
    print(f"GPU NVIDIA: {'‚úÖ' if gpu_nvidia else '‚ùå'}")
    print(f"CUDA: {'‚úÖ' if cuda_instalado else '‚ùå'}")
    print(f"PyTorch + CUDA: {'‚úÖ' if pytorch_cuda else '‚ùå'}")
    print(f"PaddlePaddle + GPU: {'‚úÖ' if paddle_gpu else '‚ùå'}")
    
    # Recomenda√ß√µes
    if gpu_nvidia and cuda_instalado:
        if not pytorch_cuda and not paddle_gpu:
            print("\nüí° RECOMENDA√á√ÉO: Instale bibliotecas com suporte GPU")
            instalar_dependencias_gpu()
        elif pytorch_cuda or paddle_gpu:
            print("\nüéâ CONFIGURA√á√ÉO OK: Voc√™ pode usar acelera√ß√£o GPU!")
            testar_performance_basica()
    else:
        print("\n‚ö†Ô∏è  LIMITA√á√ÉO: Sem GPU NVIDIA ou CUDA - apenas CPU dispon√≠vel")
        print("   PyTesseract funcionar√° normalmente em CPU")
        print("   EasyOCR e PaddleOCR tamb√©m funcionam em CPU (mais lentos)")

if __name__ == "__main__":
    main()
